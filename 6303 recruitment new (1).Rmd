---
title: "6303: Final Project"
author: "Varun Sai Thota 1002140673, Ramyasai Donkeshwaram 1002164699"
date: "2024-05-08"
output:
  pdf_document: default
  html_document: default
  word_document: default
---

```{r}
library(dplyr)
library(caret)
library(ggplot2)
library(reshape2)
library(rpart.plot)
```

```{r}
recruitmentdataset <- read.csv("~/Downloads/recruitmentdataset.csv")
View(recruitmentdataset)
```

```{r}
head(recruitmentdataset, n = 5)
```

```{r}
tail(recruitmentdataset, n = 5)
```
```{r}
recruitmentdataset$Id <- NULL
head(recruitmentdataset, n = 5)
```
```{r}
dim(recruitmentdataset)
recruitmentdataset <- unique(recruitmentdataset)
dim(recruitmentdataset)
```

```{r}
# Total Null values
total_nulls <- sum(is.na(recruitmentdataset))
print(total_nulls)
```

```{r}
# Summary of data
summary(recruitmentdataset)
```
## Checking data types 
```{r}
# Use str() function to display the structure of the dataset
str(recruitmentdataset)
```
```{r}
sapply(recruitmentdataset, class)
```

```{r}
numeric_cols <- recruitmentdataset[, sapply(recruitmentdataset, is.numeric)]
numeric_cols_names <- colnames(numeric_cols)
numeric_cols_names
```
## Outliers 


```{r}
# Visualizing class differences for numerical features

for (feature in numeric_cols_names) {
  p <- ggplot(recruitmentdataset, aes(y = !!sym(feature))) +
    geom_boxplot(fill = "steelblue", color = "black") +
    labs(title = paste("Box plot for", feature)) +
    theme_minimal() 
  print(p)
}
```
```{r}
library(dplyr)
head(select_if(recruitmentdataset, is.numeric))

```

```{r}
numeric_cols <- recruitmentdataset[, sapply(recruitmentdataset, is.numeric)]
numeric_cols_names <- colnames(numeric_cols)
numeric_cols_names
```

Plot 1 ------ box plot for each numerical column against decision

```{r}
# Visualizing class differences for numerical features

for (feature in numeric_cols_names) {
  p <- ggplot(recruitmentdataset, aes(x = decision, y = !!sym(feature))) +
    geom_boxplot(fill = "steelblue", color = "black") +
    labs(title = paste("decision Vs", feature),
         x = "decision",
         y = feature) +
    theme_minimal() 
  print(p)
}
```
Plot 2 --- Box plot for numerical columns

```{r}
# Visualizing class differences for numerical features

for (feature in numeric_cols_names) {
  p <- ggplot(recruitmentdataset, aes(y = !!sym(feature))) +
    geom_boxplot(fill = "steelblue", color = "black") +
    labs(title = paste("Box plot for", feature)) +
    theme_minimal() 
  print(p)
}
```

Plot 3 --- Correlation Plot 

```{r}
library(reshape2)
# Select numerical variables for the correlation matrix
numeric_cols <- recruitmentdataset[, sapply(recruitmentdataset, is.numeric)]
numeric_cols_names <- colnames(numeric_cols)
numeric_cols_names

# Creating the correlation matrix
corr_matrix <- cor(numeric_cols)
# Converting the correlation matrix into a data frame
corr_dataframe <- melt(corr_matrix)

# Creating heatmap
ggplot(corr_dataframe, aes(Var2, Var1, fill = abs(value), label = round(value, 2))) +
  geom_tile(color = "white") +
  geom_text(size = 3, color = "black") +  # Ajouter les valeurs de corrÃ©lation
  scale_fill_gradientn(colors = c("white","steelblue", "blue"), name="Correlation") + 
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, vjust = 1, size = 10, hjust = 1)) +
  coord_fixed() +
  labs(x = "", y = "") +
  theme(legend.position = "right")
```


```{r}
head(recruitmentdataset)
```

Plot 4 ---- Violin plot for income and age

```{r}
library(ggplot2)
# Most basic violin chart
p <- ggplot(recruitmentdataset, aes(x=decision, y=age, fill=decision)) + # fill=name allow to automatically dedicate a color for each group
  geom_violin()
p
```


## Partitioning dataset 

```{r}
# data partition
set.seed(4699)
trainIndex <- createDataPartition(recruitmentdataset$decision, p = 0.80, list = FALSE)
# 80% training data
train.data1 <- recruitmentdataset[trainIndex, ]
# 20% testing data
test.data1 <- recruitmentdataset[-trainIndex, ]
dim(train.data1)
```


```{r}
dim(test.data1)
```

```{r}
# Decision tree using Gini Index
tree_gini <- rpart(decision ~ ., data  = train.data1, method = "class", parms = list(split = "gini"))

# Plotting the decision tree with Gini Index
rpart.plot(tree_gini, main = "Decision Tree (Gini Index)", type = 4, extra = 101)
```

## Partitioning dataset 2

```{r}
# data partition
set.seed(673)
trainIndex <- createDataPartition(recruitmentdataset$decision, p = 0.80, list = FALSE)
# 80% training data
train.data2 <- recruitmentdataset[trainIndex, ]
# 20% testing data
test.data2 <- recruitmentdataset[-trainIndex, ]
dim(train.data2)
```

```{r}
# Decision tree using Gain Ratio
tree_gain_ratio <- rpart(decision ~ ., data = train.data2, method = "class", parms = list(split = "information"))

# Plotting the decision tree with Gain Ratio
rpart.plot(tree_gain_ratio, main = "Decision Tree (Gain Ratio)", type = 4, extra = 101)
```

```{r}
# control parameters Cross-Validated (10 fold) 
trctrl <- trainControl(method = "cv", classProbs = TRUE)
# fitting decision tree classification model
DTModel_gini <- train(decision ~ ., data = train.data1, method = "rpart",metric = "ROC", parms  = list(split = "gini"), trControl = trctrl)
# model summary
DTModel_gini
```

```{r}
# fitting decision tree classification model
DTModel_gain_ratio <- train(decision ~ ., data = train.data2, method = "rpart",metric = "ROC", parms  = list(split = "information"), trControl = trctrl)
# model summary
DTModel_gain_ratio
```
library(caret)

```{r}
# viasulaziation
library(rpart.plot)
prp(DTModel_gini$finalModel, box.palette = "orange", tweak = 1.2, varlen = 20)
```

```{r}
# viasulaziation
library(rpart.plot)
prp(DTModel_gain_ratio$finalModel, box.palette = "yellow", tweak = 1.2, varlen = 20)
```
```{r}
library(caret)
model_importance <- varImp(DTModel_gini)

# Convert importance data to a data frame
importance_df <- as.data.frame(model_importance$importance)

# Add column names to the data frame
importance_df <- cbind(variable_name = rownames(importance_df), importance_df)
rownames(importance_df) <- 1:nrow(importance_df)

# Sort the data frame by Overall importance score
sorted_df <- importance_df[order(-importance_df$Overall), ]
top_variables <- head(sorted_df, 8)

# Plot using ggplot2 for customization
library(ggplot2)
ggplot(top_variables, aes(x = Overall, y = reorder(variable_name, Overall), fill = Overall)) +
  geom_bar(stat = "identity") +
  scale_fill_gradient2(low = "skyblue", high = "yellow", midpoint = 50) +
  labs(x = "Overall Importance Score", y = "Variable", title = "Variable Importance - Gini") +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```

```{r}
# Predicting the model on the test dataset
predictions <- predict(DTModel_gini, test.data1, type = "prob")

# Plotting the probabilities
plot(predictions$True, 
     main = "Scatterplot of Probabilities of Default (Test Data)", 
     xlab = "Decision", 
     ylab = "Predicted Probability of Default")
```

```{r}
# predicting the model on test data set
PredDTModel_gain_ratio <- predict(DTModel_gain_ratio,test.data2, type = "prob")

# plot of probabilities
plot(PredDTModel_gain_ratio$True, 
     main = "Scatterplot of Probabilities of default (test data)", 
     xlab = "Decision", 
     ylab = "Predicted Probability of default")
```

```{r}
# taking the cut-off probability 50%
pred.DT <- ifelse(predictions$True > 0.50, "True", "False")

# saving predicted vector as factor 
Pred <- as.factor(pred.DT)

# ordering the vectors
Predicted <- ordered(Pred, levels = c("True", "False"))
Actual <- ordered(test.data1$decision,levels = c("True", "False"))

# making confusion matrix
cm <-confusionMatrix(table(Predicted,Actual))
cm
```

```{r figure-size, fig.width=6, fig.height=4}
# Convert to dataframe for ggplot
conf_df <- as.data.frame(as.table(cm))
names(conf_df) <- c("Predicted", "Actual", "Count")

# Plot confusion matrix
ggplot(data = conf_df, aes(x = Predicted, y = Actual, fill = Count)) +
  geom_tile(color = "white") +
  geom_text(aes(label = Count)) +
  scale_fill_gradient(low = "white", high = "skyblue", limits=c(0, 5000), breaks=seq(0, 5000, 1250)) +
  theme_minimal() +
  labs(x = "Predicted", y = "Actual", title = "Confusion Matrix Heatmap")
```

```{r}
# loading the package
library(ROCR)
DTPrediction <- predict(DTModel_gini, test.data1,type = "prob")
Prediction <- prediction(DTPrediction[2],test.data1$decision)
performance <- performance(Prediction, "tpr","fpr")

# plotting ROC curve
plot(performance,main = "ROC Curve",col = 2,lwd = 2)
abline(a = 0,b = 1,lwd = 2,lty = 3,col = "black")
```

```{r}
# loading the package
library(ROCR)
DTPrediction <- predict(DTModel_gain_ratio, test.data2,type = "prob")
Prediction <- prediction(DTPrediction[2],test.data2$decision)
performance <- performance(Prediction, "tpr","fpr")
# plotting ROC curve
plot(performance,main = "ROC Curve",col = 2,lwd = 2)
abline(a = 0,b = 1,lwd = 2,lty = 3,col = "black")
```
```{r}
library(ROCR)
# area under curve
DTPrediction <- predict(DTModel_gini, test.data1,type = "prob")
Prediction <- prediction(DTPrediction[2],test.data1$decision)
aucDT <- performance(Prediction, measure = "auc")
aucDT <- aucDT@y.values[[1]]
aucDT
```
```{r}
library(ROCR)
# area under curve
DTPrediction <- predict(DTModel_gain_ratio, test.data2,type = "prob")
Prediction <- prediction(DTPrediction[2],test.data2$decision)
aucDT <- performance(Prediction, measure = "auc")
aucDT <- aucDT@y.values[[1]]
aucDT
```